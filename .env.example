# GenomicLightning Environment Configuration Template
# Copy this file to .env and customize for your environment

# =============================================================================
# GPU Configuration
# =============================================================================
# Select which GPU devices to use (comma-separated list or "all")
CUDA_VISIBLE_DEVICES=0

# =============================================================================
# Weights & Biases Configuration (Optional)
# =============================================================================
# Your W&B API key for experiment tracking
# Get from: https://wandb.ai/settings
WANDB_API_KEY=

# W&B project name
WANDB_PROJECT=genomic-lightning

# W&B entity (username or team)
WANDB_ENTITY=

# =============================================================================
# PyTorch Configuration
# =============================================================================
# PyTorch cache directory
TORCH_HOME=/app/.torch

# PyTorch JIT compilation
PYTORCH_JIT=1

# =============================================================================
# Jupyter Configuration
# =============================================================================
# Jupyter token (leave empty for no token in development)
JUPYTER_TOKEN=

# Jupyter password (leave empty for no password in development)
JUPYTER_PASSWORD=

# =============================================================================
# Data Paths
# =============================================================================
# Path to training data
DATA_PATH=/app/data

# Path for model checkpoints
CHECKPOINT_PATH=/app/checkpoints

# Path for logs
LOG_PATH=/app/logs

# =============================================================================
# Training Configuration
# =============================================================================
# Default number of workers for data loading
NUM_WORKERS=4

# Default batch size
BATCH_SIZE=32

# Default learning rate
LEARNING_RATE=0.001

# =============================================================================
# Model Configuration
# =============================================================================
# Default model type
MODEL_TYPE=danq

# Default sequence length
SEQUENCE_LENGTH=1000

# Default number of classes
NUM_CLASSES=919

# =============================================================================
# Distributed Training
# =============================================================================
# Master address for distributed training
MASTER_ADDR=localhost

# Master port for distributed training
MASTER_PORT=12355

# World size (number of processes)
WORLD_SIZE=1

# Local rank
LOCAL_RANK=0

# =============================================================================
# Monitoring and Debugging
# =============================================================================
# Enable debug mode
DEBUG=false

# Enable profiler
ENABLE_PROFILER=false

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Enable memory profiling
MEMORY_PROFILE=false

# =============================================================================
# Security Settings
# =============================================================================
# JWT secret for API authentication (if using web interface)
JWT_SECRET=

# API rate limiting
API_RATE_LIMIT=100

# =============================================================================
# Performance Tuning
# =============================================================================
# Number of threads for PyTorch
OMP_NUM_THREADS=1

# CUDA memory fraction
CUDA_MEMORY_FRACTION=0.8

# Enable mixed precision training
MIXED_PRECISION=true

# Enable gradient checkpointing
GRADIENT_CHECKPOINTING=false
